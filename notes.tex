\documentclass[11pt]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{graphicx}

\def\Name{Ran Liao}
\def\Topic{Computer Networks}

\title{\textbf{\Topic}}
\author{\Name}
\markboth{Notes on \Topic\ }{Notes on \Topic\ }
\date{\today}
 
\pagestyle{fancy}
\fancyhf{}
\rhead{\date{\today} }
\lhead{Notes on \Topic\ }
\rfoot{\thepage}

\textheight=9in
%\textwidth=6.5in
\topmargin=-.75in
%\oddsidemargin=0in
%\evensidemargin=0in
 
\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Introduction}

In Internet jargon, all of these devices are called \textbf{hosts} or end \textbf{systems}.
End systems are connected together by a network of \textbf{communication links} and \textbf{packet switches}.
Packet switches come in many shapes and flavors, but the two most prominent types in today’s Internet are \textbf{routers} and \textbf{link-layer switches}.
The sequence of communication links and packet switches traversed by a packet from the sending end system to the receiving end system is known as a \textbf{route} or \textbf{path} through the network.
End systems access the Internet through \textbf{Internet Service Providers (ISPs)}.

\section{Circuit Switching versus Packet Switching}

There are two fundamental approaches to moving data through a network of links and switches: \textbf{circuit switching} and \textbf{packet switching}. 

\subsection{Packet Switching}

In a network application, end systems exchange messages with each other. To send a message from a source end system to a destination end system, the source breaks long messages into smaller chunks of data known as \textbf{packets}. Between source and destination, each packet travels through communication links and packet switches.

\subsection{Circuit Switching}

In circuit-switched networks, the resources needed along a path (buffers, link transmission rate) to provide for communication between the end systems are \textit{reserved} for the duration of the communication session between the end systems.


\subsubsection{FDM : Frequency-Division Multiplexing}
	
	With FDM, the frequency spectrum of a link is divided up among the connections established across the link. Specifically, the link dedicates a frequency band to each connection for the duration of the connection.
	
\subsubsection{TDM : Time-Division Multiplexing}
	
	For a TDM link, time is divided into frames of fixed duration, and each frame is divided into a fixed number of time slots. When the network establishes a connection across a link, the network dedicates one time slot in every frame to this connection. These slots are dedicated for the sole use of that connection, with one time slot available for use (in every frame) to transmit the connection’s data.
	
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/FDMvsTDM.png}
	\caption{FDM versus TDM}
	\label{fig:FDMvsTDM}
\end{figure}

\subsection{Trade-off}

Packet Switching is not suitable for real-time services because of its variable and unpredictable end-to-end delays (due primarily to variable and unpredictable queuing delays). Proponents of packet switching argue that (1) it offers better sharing of transmission capacity than circuit switching and (2) it is simpler, more efficient, and less costly to implement than circuit switching.

Circuit switching pre-allocates use of the transmission link \textit{regardless of demand}, with allocated but unneeded link time going unused. Packet switching on the other hand allocates link use \textit{on demand}. Link transmission capacity will be shared on a packet-by-packet basis only among those users who have packets that need to be transmitted over the link.

\section{Delay}

Denote $d_{proc}$, $d_{queue}$, $d_{trans}$, and $d_{prop}$ to be the processing, queuing, transmission, and propagation delays respectively. Then the total nodal delay is given by

\[
	d_{nodal} = d_{proc} + d_{queue} + d_{trans} + d_{prop}
\]

\subsection{Processing Delay}

The time required to examine the packet’s header and determine where to direct the packet is part of the processing delay.

\subsection{Queuing Delay}

Each packet switch has multiple links attached to it. For each attached link, the packet switch has an \textbf{output buffer} (also called an \textbf{output queue}), which stores packets that the router is about to send into that link. If an arriving packet needs to be transmitted onto a link but finds the link busy with the transmission of another packet, the arriving packet must wait in the output buffer. The \textbf{queuing delays} is the time packet waits to be transmitted in the output queue. These delays are variable and depend on the level of congestion in the network. 

Since the amount of buffer space is finite, an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, \textbf{packet loss} will occur --- either the arriving packet or one of the already-queued packets will be dropped.

Denote $a$ to be the average rate at which packets arrive at the queue (in units of packets/sec). The ratio $\frac{aL}{R}$ is called the \textbf{traffic intensity}. If  $\frac{aL}{R} > 1$, then the average rate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted from the queue. In this unfortunate situation, the queue will tend to increase without bound and the queuing delay will approach infinity.

\subsection{Transmission Delay}

Most packet switches use \textbf{store-and-forward transmission} at the inputs to the links. Store-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. Consider the general case of sending one packet of $L$ \textit{bits} over a link with rate $R$ \textit{bits/sec}. Then the \textbf{transmission delay} is $\frac{L} {R}$ \textit{seconds}.

\subsection{Propagation Delay}

The propagation delay is the distance between two routers divided by the propagation speed. The propagation speed depends on the physical medium of the link and is in the range of $2 \cdot 10^8$ \textit{meters/sec} to $3 \cdot 10^8$ \textit{meters/sec}.

\subsection{Clarification}

The \textbf{transmission delay} is the amount of time required for the router to push out the packet; it is a function of the packet’s length and the transmission rate of the link, but has nothing to do with the distance between the two routers. The \textbf{propagation delay}, on the other hand, is the time it takes a bit to propagate from one router to the next; it is a function of the distance between the two routers, but has nothing to do with the packet’s length or the transmission rate of the link.

\section{Protocol Layers and Their Service Models}

To provide structure to the design of network protocols, network designers organize protocols—and the network hardware and software that implement the protocols— in \textbf{layers}. We are interested in the \textbf{services} that a layer offers to the layer above—the so-called \textbf{service model} of a layer. When taken together, the protocols of the various layers are called the \textbf{protocol stack}.

\subsection{Network Layer}

The Internet’s network layer is responsible for moving network-layer packets known as datagrams from one host to another.

\subsection{Link Layer}

The Internet’s network layer routes a datagram through a series of routers between the source and destination. To move a packet from one node (host or router) to the next node in the route, the network layer relies on the services of the link layer.

\subsection{Physical Layer}

While the job of the link layer is to move entire frames from one network element to an adjacent network element, the job of the physical layer is to move the individual bits within the frame from one node to the next.

\section{Security Threats}

\begin{itemize}
	\item \textbf{Denial-of-Service (DoS)}
	\item \textbf{Sniffing}
	\item \textbf{Spoofing}
\end{itemize}

\section{Application Layer}

The application layer is where network applications and their application-layer protocols reside. The Internet's application layer includes many protocols, such as the HTTP, SMTP, FTP and DNS.

\subsection{Transport Services Available to Applications}

\subsubsection{Reliable Data Transfer}

If a protocol provides a guaranteed data delivery service, it is said to provide \textbf{reliable data transfer}. When a transport-layer protocol doesn’t provide reliable data transfer, some of the data sent by the sending process may never arrive at the receiving process. This may be acceptable for \textbf{loss-tolerant applications}.

\subsubsection{Throughput}

A transport-layer protocol may provide guaranteed available throughput at some specified rate. Applications that have throughput requirements are said to be \textbf{bandwidth-sensitive applications}, whereas \textbf{elastic applications} can make use of as much, or as little, throughput as happens to be available.

\subsubsection{Timing}

A transport-layer protocol can also provide timing guarantees.

\subsubsection{Security}

A transport protocol can provide an application with one or more security services.

\subsection{Network Application Architectures}

\subsubsection{Client-Server Architecture}

In a client-server architecture, there is an always-on host, called the \textbf{server}, which services requests from many other hosts, called \textbf{clients}. Often in a client-server application, a single-server host is incapable of keeping up with all the requests from clients. For this reason, a \textbf{data center}, housing a large number of hosts, is often used to create a powerful virtual server. 

\subsubsection{P2P Architecture}

In a P2P architecture, there is minimal (or no) reliance on dedicated servers in data centers. Instead the application exploits direct communication between pairs of intermittently connected hosts, called \textbf{peers}. One of the most compelling features of P2P architectures is their \textbf{self-scalability}. P2P architectures are also cost effective, since they normally don’t require significant server infrastructure and server bandwidth. However, P2P applications face challenges of security, performance, and reliability due to their highly decentralized structure.


\subsection{HTTP : HyperText Transfer Protocol}

HTTP is implemented in two programs: a client program and a server program. The client program and server program, executing on different end systems, talk to each other by exchanging HTTP messages.
HTTP is mainly a \textbf{pull protocol} --- someone loads information on a Web server and users use HTTP to pull the information from the server at their convenience.
Because an HTTP server maintains no information about the clients, HTTP is said to be a \textbf{stateless protocol}.
If each request/response pair be sent over a separate TCP connection, the application is said to use \textbf{non-persistent connections}. If all of the requests and their corresponding responses be sent over the same TCP connection, the application is said to use \textbf{persistent connections}. HTTP can use both non-persistent connections and persistent connections.

\subsubsection{HTTP Request Message}

~\ 

\texttt{GET /somedir/page.html HTTP/1.1}

\texttt{Host: www.someschool.edu}

\texttt{Connection: close}

\texttt{User-agent: Mozilla/5.0}

\texttt{Accept-language: fr}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/HttpRequest.png}
	\caption{General format of an HTTP request message}
	\label{fig:HttpRequest}
\end{figure}

\subsubsection{HTTP Response Message}

~\

\texttt{HTTP/1.1 200 OK}

\texttt{Connection: close}

\texttt{Date: Tue, 18 Aug 2015 15:44:04 GMT}

\texttt{Server: Apache/2.2.3 (CentOS)}

\texttt{Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT}

\texttt{Content-Length: 6821}

\texttt{Content-Type: text/html}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/HttpResponse.png}
	\caption{General format of an HTTP response message}
	\label{fig:HttpResponse}
\end{figure}

\subsubsection{Common HTTP Status Codes}

\begin{itemize}
	\item \textbf{200 OK}
	
	Request succeeded and the information is returned in the response.
	
	\item \textbf{301 Moved Permanently}
	
	Requested object has been permanently moved; the new URL is specified in \textit{Location} header of the response message. The client software will automatically retrieve the new URL.
	
	\item \textbf{400 Bad Request}
	
	This is a generic error code indicating that the request could not be understood by the server.
	
	\item \textbf{404 Not Found}
	
	The requested document does not exist on this server.
	
	\item \textbf{505 HTTP Version Not Supported}
	
	 The requested HTTP protocol version is not supported by the server.
	 
\end{itemize}

\subsection{SMTP : Simple Mail Transfer Protocol}

SMTP transfers messages from senders’ mail servers to the recipients’ mail servers.
And it is primarily a \textbf{push protocol} --- the sending mail server pushes the file to the receiving mail server.
Although SMTP has numerous wonderful qualities, it is nevertheless a legacy technology that possesses certain archaic characteristics. For example, it restricts the body (not just the headers) of all mail messages to simple 7-bit ASCII. It requires binary multimedia data to be encoded to ASCII before being sent over SMTP; and it requires the corresponding ASCII message to be decoded back to binary after SMTP transport.

~\

\texttt{telnet serverName 25}

\texttt{S: 220 hamburger.edu}

\texttt{C: HELO crepes.fr}

\texttt{S: 250 Hello crepes.fr, pleased to meet you}

\texttt{C: MAIL FROM: <alice@crepes.fr>}

\texttt{S: 250 alice@crepes.fr ... Sender ok}

\texttt{C: RCPT TO: <bob@hamburger.edu>}

\texttt{S: 250 bob@hamburger.edu ... Recipient ok}

\texttt{C: DATA}

\texttt{S: 354 Enter mail, end with ”.” on a line by itself}

\texttt{C: Do you like ketchup?}

\texttt{C: How about pickles?}

\texttt{C: .}

\texttt{S: 250 Message accepted for delivery}

\texttt{C: QUIT}

\texttt{S: 221 hamburger.edu closing connection}

\subsection{POP3 : Post Office Protocol --- Version 3}

POP3 begins when the user agent opens a TCP connection to the mail server on port 110. With the TCP connection established, POP3 progresses through three phases: authorization, transaction, and update. 

\begin{itemize}
	\item During the first phase, authorization, the user agent sends a username and a password (in the clear) to authenticate the user.
	
	\texttt{telnet mailServer 110}

	\texttt{+OK POP3 server ready}

	\texttt{user bob}

	\texttt{+OK}

	\texttt{pass hungry}

	\texttt{+OK user successfully logged on}
	
	\item During the second phase, transaction, the user agent retrieves messages; also during this phase, the user agent can mark messages for deletion, remove deletion marks, and obtain mail statistics.
	
	\texttt{C: list}
	
	\texttt{S: 1 498 }
	
	\texttt{S: 2 912 }
	
	\texttt{S: .}
	
	\texttt{C: retr 1}
	
	\texttt{S: (blah blah ...}
	
	\texttt{S: .................}
	
	\texttt{S: ..........blah)}
	
	\texttt{S: .}
	
	\texttt{C: dele 1}
	
	\texttt{C: retr 2}
	
	\texttt{S: (blah blah ... }
	
	\texttt{S: .................}
	
	\texttt{S: ..........blah)}
	
	\texttt{S: .}
	
	\texttt{C: dele 2}

	\texttt{C: quit}
	
	\texttt{S: +OK POP3 server signing off}

	
	\item The third phase, update, occurs after the client has issued the quit command, ending the POP3 session; at this time, the mail server deletes the messages that were marked for deletion.
\end{itemize}

\subsection{IMAP : Internet Mail Access Protocol}

An IMAP server will associate each message with a folder; when a message first arrives at the server, it is associated with the recipient’s INBOX folder. The recipient can then move the message into a new, user-created folder, read the message, delete the message, and so on. The IMAP protocol provides commands to allow users to create folders and move messages from one folder to another. IMAP also provides commands that allow users to search remote folders for messages matching specific criteria. Another important feature of IMAP is that it has commands that permit a user agent to obtain components of messages. For example, a user agent can obtain just the message header of a message or just one part of a multipart MIME message.

\subsection{DNS : Domain Name System}

The DNS is (1) a distributed database that translates hostnames to IP addresses and implemented in a hierarchy of DNS servers, and (2) an application-layer protocol that allows hosts to query the distributed database. DNS provides a few other important services in addition to translating hostnames to IP addresses:

\begin{itemize}
	\item \textbf{Host aliasing}
	
	A host with a complicated hostname can have one or more alias names.
	
	\item \textbf{Mail server aliasing}
	
	DNS can be invoked by a mail application to obtain the canonical hostname for a supplied alias hostname as well as the IP address of the host.
	
	\item \textbf{Load distribution}
	
	DNS is also used to perform load distribution among replicated servers, such as replicated Web servers.
\end{itemize}

\subsubsection{Distributed and Hierarchical DNS Structure}

\begin{itemize}
	\item \textbf{Root DNS servers}
	
	Root name servers provide the IP addresses of the TLD servers.
	
	\item \textbf{Top-level domain (TLD) servers}
	
	For each of the top-level domains,  there is TLD server (or server cluster).
	
	\item \textbf{Authoritative DNS servers}
	
	Every organization with publicly accessible hosts (such as Web servers and mail servers) on the Internet must provide publicly accessible DNS records that map the names of those hosts to IP addresses. An organization’s authoritative DNS server houses these DNS records.
	
\end{itemize}

There is another important type of DNS server called the \textbf{local DNS server}. A local DNS server does not strictly belong to the hierarchy of servers but is nevertheless central to the DNS architecture. Each ISP has a local DNS server (also called a default name server). When a host connects to an ISP, the ISP provides the host with the IP addresses of one or more of its local DNS servers. When a host makes a DNS query, the query is sent to the local DNS server, which acts a proxy, forwarding the query into the DNS server hierarchy,

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/DNS.png}
	\caption{hierarchy of DNS servers}
	\label{fig:DNS}
\end{figure}

\subsubsection{RR : Resource Record}

A resource record is a four-tuple that contains the following fields: 

\texttt{(Name, Value, Type, TTL)}

\texttt{TTL} is the time to live of the resource record; it determines when a resource should be removed from a cache.
The meaning of \texttt{Name} and \texttt{Value} depend on \texttt{Type}:

\begin{itemize}
	\item 
	
	If \texttt{Type=A}, then \texttt{Name} is a hostname and \texttt{Value} is the IP address for the hostname. Thus, a \texttt{Type A} record provides the standard hostname-to-IP address mapping. 
	
	As an example, \texttt{(relay1.bar.foo.com, 145.37.93.126, A)} is a \texttt{Type A} record.
	
	\item
	
	If \texttt{Type=NS}, then \texttt{Name} is a domain (such as foo.com) and \texttt{Value} is the hostname of an authoritative DNS server that knows how to obtain the IP addresses for hosts in the domain. This record is used to route DNS queries further along in the query chain. 
	
	As an example, \texttt{(foo.com, dns.foo.com, NS)} is a \texttt{Type NS} record.
	
	\item
	
	If \texttt{Type=CNAME}, then \texttt{Value} is a canonical hostname for the alias hostname Name. This record can provide querying hosts the canonical name for a hostname. 
	
	As an example, \texttt{(foo.com, relay1.bar.foo.com, CNAME)} is a \texttt{CNAME} record.
	
	\item
	
	If \texttt{Type=MX}, then Value is the canonical name of a mail server that has an alias hostname Name. \texttt{MX} records allow the hostnames of mail servers to have simple aliases.
	
	As an example, \texttt{(foo.com, mail.bar.foo.com, MX)} is an \texttt{MX} record. 
	
\end{itemize}

\subsubsection{DNS Messages}

\begin{itemize}

	\item 
	
	The first 12 bytes is the \textit{header section}, which has a number of fields. The first field is a 16-bit number that identifies the query. This identifier is copied into the reply message to a query, allowing the client to match received replies with sent queries. There are a number of flags in the flag field. A 1-bit query/reply flag indicates whether the message is a query (0) or a reply (1). A 1-bit authoritative flag is set in a reply message when a DNS server is an authoritative server for a queried name. A 1-bit recursion-desired flag is set when a client (host or DNS server) desires that the DNS server perform recursion when it doesn’t have the record. A 1-bit recursion-available field is set in a reply if the DNS server supports recursion. In the header, there are also four number-of fields. These fields indicate the number of occurrences of the four types of data sections that follow the header.
	
	\item
	
	The \textit{question section} contains information about the query that is being made. This section includes (1) a name field that contains the name that is being queried, and (2) a type field that indicates the type of question being asked about the name—for example, a host address associated with a name (\texttt{Type A}) or the mail server for a name (\texttt{Type MX}).
	
	\item
	
	In a reply from a DNS server, the \textit{answer section} contains the resource records for the name that was originally queried.
	
	\item
	
	The \textit{authority section} contains records of other authoritative servers.
	
	\item
	
	The \textit{additional section} contains other helpful records.


\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/DnsMessage.png}
	\caption{DNS message format}
	\label{fig:DnsMessage}
\end{figure}

\subsection{Peer-to-Peer File Distribution}

Denote the upload rate of the server’s access link by $u_s$, the upload rate of the $i$th peer’s access link by $u_i$, and the download rate of the $i$th peer’s access link by $d_i$. Also denote the size of the file to be distributed (in bits) by $F$ and the number of peers that want to obtain a copy of the file by $N$. 

\subsubsection{Distribution Time for the Client-Server Architecture}

\begin{itemize}
	\item 
	
	The server must transmit one copy of the file to each of the $N$ peers. Thus the server must transmit $NF$ bits. Since the server’s upload rate is $u_s$, the time to distribute the file must be at least $\frac{NF}{u_s}$.
	
	\item
	
	Let $d_{min}$ denote the download rate of the peer with the lowest download rate. The peer with the lowest download rate cannot obtain all $F$ bits of the file in less than $\frac{F}{d_{min}}$ seconds. Thus the minimum distribution time is at least $\frac{F}{d_{min}}$.
	
\end{itemize}

Putting these two observations together, we obtain

\[
	D_{cs} \ge \max \{\frac{NF}{u_s}, \frac{F}{d_{min}} \}
\]

This distribution time increases linearly with the number of peers $N$.

\subsubsection{Distribution Time for the P2P Architecture}

\begin{itemize}
	\item 
	
	At the beginning of the distribution, only the server has the file. To get this file into the community of peers, the server must send each bit of the file at least once into its access link. Thus, the minimum distribution time is at least $\frac{F}{u_s}$.
	
	\item
	
	The peer with the lowest download rate cannot obtain all $F$ bits of the file in less than $\frac{F}{d_{min}}$ seconds. Thus the minimum distribution time is at least $\frac{F}{d_{min}}$.
	
	\item
	
	Finally, observe that the total upload capacity of the system as a whole is equal to the upload rate of the server plus the upload rates of each of the individual peers, that is, $u_{total} = u_s + \sum_{i=1}^N u_i$. The system must deliver (upload) $F$ bits to each of the $N$ peers, thus delivering a total of $NF$ bits. This cannot be done at a rate faster than $u_{total}$. Thus, the minimum distribution time is also at least $\frac{NF}{u_s + \sum_{i=1}^N u_i}$.
	
\end{itemize}

Putting these three observations together, we obtain

\[
	D_{P2P} \ge \max \{\frac{F}{u_s}, \frac{F}{d_{min}}, \frac{NF}{u_s + \sum_{i=1}^N u_i} \}
\]

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{images/DistributionTime.png}
	\caption{Distribution time for P2P and client-server architectures}
	\label{fig:DistributionTime}
\end{figure}

\subsection{BitTorrent}

BitTorrent is a popular P2P protocol for file distribution. In BitTorrent lingo, the collection of all peers participating in the distribution of a particular file is called a \textbf{torrent}. Peers in a torrent download equal-size \textbf{chunks} of the file from one another, with a typical chunk size of 256 \textit{kbytes}. 

When a peer first joins a torrent, it has no chunks. Over time it accumulates more and more chunks. While it downloads chunks it also uploads chunks to other peers. Once a peer has acquired the entire file, it may (selfishly) leave the torrent, or (altruistically) remain in the torrent and continue to upload chunks to other peers. Also, any peer may leave the torrent at any time with only a subset of chunks, and later rejoin the torrent.

 Each torrent has an infrastructure node called a \textbf{tracker}. When a peer joins a torrent, it registers itself with the tracker and periodically informs the tracker that it is still in the torrent. In this manner, the tracker keeps track of the peers that are participating in the torrent.
 
When a new peer, Alice, joins the torrent, the tracker randomly selects a subset of peers from the set of participating peers, and sends the IP addresses of these 50 peers to Alice. Possessing this list of peers, Alice attempts to establish concurrent TCP connections with all the peers on this list. Let’s call all the peers with which Alice succeeds in establishing a TCP connection ``neighboring peers". At any given time, each peer will have a subset of chunks from the file, with different peers having different subsets. Periodically, Alice will ask each of her neighboring peers for the list of the chunks they have. With this knowledge, Alice will issue requests for chunks she currently does not have.

In deciding which chunks to request, Alice uses a technique called \textbf{rarest first}. The idea is to determine, from among the chunks she does not have, the chunks that are the rarest among her neighbors and then request those rarest chunks first. In this manner, the rarest chunks get more quickly redistributed, aiming to (roughly) equalize the numbers of copies of each chunk in the torrent.

To determine which requests she responds to, BitTorrent uses a clever trading algorithm. The basic idea is that Alice gives priority to the neighbors that are currently supplying her data at the \textbf{highest rate}. Specifically, for each of her neighbors, Alice continually measures the rate at which she receives bits and determines the four peers that are feeding her bits at the highest rate. She then reciprocates by sending chunks to these same four peers. Every 10 seconds, she recalculates the rates and possibly modifies the set of four peers. In BitTorrent lingo, these four peers are said to be \textbf{unchoked}. Importantly, every 30 seconds, she also picks one additional neighbor at random and sends it chunks. Let’s call the randomly chosen peer Bob. In BitTorrent lingo, Bob is said to be \textbf{optimistically unchoked}. Because Alice is sending data to Bob, she may become one of Bob’s top four uploaders, in which case Bob would start to send data to Alice. If the rate at which Bob sends data to Alice is high enough, Bob could then, in turn, become one of Alice’s top four uploaders. In other words, every 30 seconds, Alice will randomly choose a new trading partner and initiate trading with that partner. If the two peers are satisfied with the trading, they will put each other in their top four lists and continue trading with each other until one of the peers finds a better partner. The effect is that peers capable of uploading at compatible rates tend to find each other. The random neighbor selection also allows new peers to get chunks, so that they can have something to trade. All other neighboring peers besides these five peers (four ``top" peers and one probing peer) are ``choked", that is, they do not receive any chunks from Alice.

\subsection{DASH : Dynamic Adaptive Streaming over HTTP}

In DASH, the video is encoded into several different versions, with each version having a different bit rate and, correspondingly, a different quality level. The client dynamically requests chunks of video segments of a few seconds in length. When the amount of available bandwidth is high, the client naturally selects chunks from a high-rate version; and when the available bandwidth is low, it naturally selects from a low-rate version. The client selects different chunks one at a time with HTTP GET request messages.

\subsection{CDNs : Content Distribution Networks}

A CDN manages servers in multiple geographically distributed locations, stores copies of the videos (and other types of Web content, including documents, images, and audio) in its servers, and attempts to direct each user request to a CDN location that will provide the best user experience. CDNs typically adopt one of two different server placement philosophies,

\begin{itemize}

	\item \textbf{Enter Deep}
	
	Deploy server clusters in access ISPs all over the world. The goal is to get close to end users, thereby improving user-perceived delay and throughput by decreasing the number of links and routers between the end user and the CDN server from which it receives content. Because of this highly distributed design, the task of maintaining and managing the clusters becomes challenging.
	
	\item \textbf{Bring Home}
	
	Bring the ISPs home by building large clusters at a smaller number (for example, tens) of sites. Instead of getting inside the access ISPs, these CDNs typically place their clusters in Internet Exchange Points (IXPs). Compared with the enter-deep design philosophy, the bring-home design typically results in lower maintenance and management overhead, possibly at the expense of higher delay and lower throughput to end users.

\end{itemize}






\newpage
\section{Transport Layer}

The Internet’s transport layer transports application-layer messages between application endpoints. In the Internet there are two transport protocols, TCP and UDP, either of which can transport application-layer messages. 

\subsection{TCP : }

\subsubsection{Connection-Oriented Service}

TCP has the client and server exchange transport-layer control information with each other before the application-level messages begin to flow. This so-called handshaking procedure alerts the client and server, allowing them to prepare for an onslaught of packets. After the handshaking phase, a TCP connection is said to exist between the sockets of the two processes.

\subsubsection{Reliable Data Transfer Service}

The communicating processes can rely on TCP to deliver all data sent without error and in the proper order.

\subsubsection{Congestion-Control Mechanism}

\subsection{UDP : }

\subsubsection{Connectionless Service}

There is no handshaking before the two processes start to communicate.

\subsubsection{Unreliable Data Transfer Service}

UDP provides an unreliable data transfer service --- that is, when a process sends a message into a UDP socket, UDP provides no guarantee that the message will ever reach the receiving process. Furthermore, messages that do arrive at the receiving process may arrive out of order.

\section{Terminology}

\begin{itemize}

	\item \textbf{RTT : Round-Trip Time}

\end{itemize}


\end{document}